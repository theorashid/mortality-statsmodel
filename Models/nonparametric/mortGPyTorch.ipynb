{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatiotemporal mortality modelling using Gaussian process regression\n",
    "Aim: model the death rate in each spatial unit (LSOA in London) over the years 2002-2017 for 19 age groups (0, 1-4, 5-9, 10-14, ..., 80-94, 85+). (Note this is simulated data due to the sensitivity of health records, and this dataset only covers 2004-2017.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import pyro\n",
    "import tqdm\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "Load the mortality dataset and the centroids of each LSOA.\n",
    "\n",
    "There is also the option to load a subset of the data covering only Hammersmith and Fulham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED LONDON DATA\n"
     ]
    }
   ],
   "source": [
    "data_path   = \"/rds/general/user/tar15/home/mortality-statsmodel/Data/\"\n",
    "\n",
    "hammersmith = False\n",
    "if hammersmith:\n",
    "    mortality = pd.read_csv(data_path + \"mortsim_hf\" + \".csv\")\n",
    "    print(\"LOADED HAMMERSMITH DATA\")\n",
    "else:\n",
    "    mortality = pd.read_csv(data_path + \"mortsim\" + \".csv\")\n",
    "    print(\"LOADED LONDON DATA\")\n",
    "mortality = mortality[[\n",
    "    \"LAD2011\", \"MSOA2011\", \"LSOA2011\", \"YEAR\", \"age_group\", \"sex\", \"deaths\", \"population\", \"IMD.score\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAD2011</th>\n",
       "      <th>MSOA2011</th>\n",
       "      <th>LSOA2011</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>age_group</th>\n",
       "      <th>sex</th>\n",
       "      <th>deaths</th>\n",
       "      <th>population</th>\n",
       "      <th>IMD.score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>2004</td>\n",
       "      <td>1_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>2004</td>\n",
       "      <td>5_9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>6.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>2004</td>\n",
       "      <td>10_14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>2004</td>\n",
       "      <td>15_19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572215</th>\n",
       "      <td>E09000011</td>\n",
       "      <td>E02006931</td>\n",
       "      <td>E01033746</td>\n",
       "      <td>2017</td>\n",
       "      <td>65_69</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>22.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572216</th>\n",
       "      <td>E09000011</td>\n",
       "      <td>E02006931</td>\n",
       "      <td>E01033746</td>\n",
       "      <td>2017</td>\n",
       "      <td>70_74</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>22.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572217</th>\n",
       "      <td>E09000011</td>\n",
       "      <td>E02006931</td>\n",
       "      <td>E01033746</td>\n",
       "      <td>2017</td>\n",
       "      <td>75_79</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>22.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572218</th>\n",
       "      <td>E09000011</td>\n",
       "      <td>E02006931</td>\n",
       "      <td>E01033746</td>\n",
       "      <td>2017</td>\n",
       "      <td>80_84</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>22.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572219</th>\n",
       "      <td>E09000011</td>\n",
       "      <td>E02006931</td>\n",
       "      <td>E01033746</td>\n",
       "      <td>2017</td>\n",
       "      <td>85+</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>22.292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2572220 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           LAD2011   MSOA2011   LSOA2011  YEAR age_group  sex  deaths  \\\n",
       "0        E09000001  E02000001  E01000001  2004         0    1       0   \n",
       "1        E09000001  E02000001  E01000001  2004       1_4    1       0   \n",
       "2        E09000001  E02000001  E01000001  2004       5_9    1       0   \n",
       "3        E09000001  E02000001  E01000001  2004     10_14    1       0   \n",
       "4        E09000001  E02000001  E01000001  2004     15_19    1       0   \n",
       "...            ...        ...        ...   ...       ...  ...     ...   \n",
       "2572215  E09000011  E02006931  E01033746  2017     65_69    2       2   \n",
       "2572216  E09000011  E02006931  E01033746  2017     70_74    2       2   \n",
       "2572217  E09000011  E02006931  E01033746  2017     75_79    2       4   \n",
       "2572218  E09000011  E02006931  E01033746  2017     80_84    2       1   \n",
       "2572219  E09000011  E02006931  E01033746  2017       85+    2       5   \n",
       "\n",
       "         population  IMD.score  \n",
       "0                 3      6.520  \n",
       "1                17      6.520  \n",
       "2                16      6.520  \n",
       "3                 8      6.520  \n",
       "4                10      6.520  \n",
       "...             ...        ...  \n",
       "2572215          36     22.292  \n",
       "2572216          37     22.292  \n",
       "2572217          33     22.292  \n",
       "2572218          33     22.292  \n",
       "2572219          22     22.292  \n",
       "\n",
       "[2572220 rows x 9 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = pd.read_csv(data_path + \"ldn_centroids\" + \".csv\")\n",
    "centroids = centroids[[\"LSOA2011\", \"name\", \"coords.x1\", \"coords.x2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA2011</th>\n",
       "      <th>name</th>\n",
       "      <th>coords.x1</th>\n",
       "      <th>coords.x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>532150.839566</td>\n",
       "      <td>181617.460916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E01000002</td>\n",
       "      <td>City of London 001B</td>\n",
       "      <td>532443.368721</td>\n",
       "      <td>181643.602822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E01000003</td>\n",
       "      <td>City of London 001C</td>\n",
       "      <td>532205.546324</td>\n",
       "      <td>182030.047059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E01000005</td>\n",
       "      <td>City of London 001E</td>\n",
       "      <td>533620.049037</td>\n",
       "      <td>181152.840191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E01000006</td>\n",
       "      <td>Barking and Dagenham 016A</td>\n",
       "      <td>544933.448417</td>\n",
       "      <td>184296.481282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>E01033742</td>\n",
       "      <td>Greenwich 007F</td>\n",
       "      <td>544442.251463</td>\n",
       "      <td>179692.607185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>E01033743</td>\n",
       "      <td>Greenwich 002H</td>\n",
       "      <td>545762.511775</td>\n",
       "      <td>180757.894534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4832</th>\n",
       "      <td>E01033744</td>\n",
       "      <td>Greenwich 007G</td>\n",
       "      <td>544539.564412</td>\n",
       "      <td>179303.703292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4833</th>\n",
       "      <td>E01033745</td>\n",
       "      <td>Greenwich 002I</td>\n",
       "      <td>546168.615531</td>\n",
       "      <td>180007.327034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>E01033746</td>\n",
       "      <td>Greenwich 038E</td>\n",
       "      <td>538053.851750</td>\n",
       "      <td>177045.460068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4835 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LSOA2011                       name      coords.x1      coords.x2\n",
       "0     E01000001        City of London 001A  532150.839566  181617.460916\n",
       "1     E01000002        City of London 001B  532443.368721  181643.602822\n",
       "2     E01000003        City of London 001C  532205.546324  182030.047059\n",
       "3     E01000005        City of London 001E  533620.049037  181152.840191\n",
       "4     E01000006  Barking and Dagenham 016A  544933.448417  184296.481282\n",
       "...         ...                        ...            ...            ...\n",
       "4830  E01033742             Greenwich 007F  544442.251463  179692.607185\n",
       "4831  E01033743             Greenwich 002H  545762.511775  180757.894534\n",
       "4832  E01033744             Greenwich 007G  544539.564412  179303.703292\n",
       "4833  E01033745             Greenwich 002I  546168.615531  180007.327034\n",
       "4834  E01033746             Greenwich 038E  538053.851750  177045.460068\n",
       "\n",
       "[4835 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The centres of the age groups have been calculated as the life expectancy from mean death rates of each age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_centres = [\n",
    "    0.05649526, 2.63893940, 7.50000000, 12.50000000, 17.65215935, 22.52097029, 27.51978992, 32.55024244,\n",
    "    37.69773327, 42.76370351, 47.71774779, 52.77291601, 57.70702200, 62.63892450, 67.63190211, 72.41333635,\n",
    "    77.36997872, 82.26084695, 89.96681347 \n",
    "]\n",
    "\n",
    "age_dict = dict(zip(mortality[\"age_group\"].unique(), age_centres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAD2011</th>\n",
       "      <th>MSOA2011</th>\n",
       "      <th>LSOA2011</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>age_group</th>\n",
       "      <th>sex</th>\n",
       "      <th>deaths</th>\n",
       "      <th>population</th>\n",
       "      <th>IMD.score</th>\n",
       "      <th>name</th>\n",
       "      <th>coords.x1</th>\n",
       "      <th>coords.x2</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.520</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>532150.839566</td>\n",
       "      <td>181617.460916</td>\n",
       "      <td>0.056495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>2004</td>\n",
       "      <td>1_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6.520</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>532150.839566</td>\n",
       "      <td>181617.460916</td>\n",
       "      <td>2.638939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>2004</td>\n",
       "      <td>5_9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>6.520</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>532150.839566</td>\n",
       "      <td>181617.460916</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>2004</td>\n",
       "      <td>10_14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6.520</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>532150.839566</td>\n",
       "      <td>181617.460916</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E02000001</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>2004</td>\n",
       "      <td>15_19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.520</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>532150.839566</td>\n",
       "      <td>181617.460916</td>\n",
       "      <td>17.652159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572215</th>\n",
       "      <td>E09000011</td>\n",
       "      <td>E02006931</td>\n",
       "      <td>E01033746</td>\n",
       "      <td>2017</td>\n",
       "      <td>65_69</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>22.292</td>\n",
       "      <td>Greenwich 038E</td>\n",
       "      <td>538053.851750</td>\n",
       "      <td>177045.460068</td>\n",
       "      <td>67.631902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572216</th>\n",
       "      <td>E09000011</td>\n",
       "      <td>E02006931</td>\n",
       "      <td>E01033746</td>\n",
       "      <td>2017</td>\n",
       "      <td>70_74</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>22.292</td>\n",
       "      <td>Greenwich 038E</td>\n",
       "      <td>538053.851750</td>\n",
       "      <td>177045.460068</td>\n",
       "      <td>72.413336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572217</th>\n",
       "      <td>E09000011</td>\n",
       "      <td>E02006931</td>\n",
       "      <td>E01033746</td>\n",
       "      <td>2017</td>\n",
       "      <td>75_79</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>22.292</td>\n",
       "      <td>Greenwich 038E</td>\n",
       "      <td>538053.851750</td>\n",
       "      <td>177045.460068</td>\n",
       "      <td>77.369979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572218</th>\n",
       "      <td>E09000011</td>\n",
       "      <td>E02006931</td>\n",
       "      <td>E01033746</td>\n",
       "      <td>2017</td>\n",
       "      <td>80_84</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>22.292</td>\n",
       "      <td>Greenwich 038E</td>\n",
       "      <td>538053.851750</td>\n",
       "      <td>177045.460068</td>\n",
       "      <td>82.260847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572219</th>\n",
       "      <td>E09000011</td>\n",
       "      <td>E02006931</td>\n",
       "      <td>E01033746</td>\n",
       "      <td>2017</td>\n",
       "      <td>85+</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>22.292</td>\n",
       "      <td>Greenwich 038E</td>\n",
       "      <td>538053.851750</td>\n",
       "      <td>177045.460068</td>\n",
       "      <td>89.966813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2572220 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           LAD2011   MSOA2011   LSOA2011  YEAR age_group  sex  deaths  \\\n",
       "0        E09000001  E02000001  E01000001  2004         0    1       0   \n",
       "1        E09000001  E02000001  E01000001  2004       1_4    1       0   \n",
       "2        E09000001  E02000001  E01000001  2004       5_9    1       0   \n",
       "3        E09000001  E02000001  E01000001  2004     10_14    1       0   \n",
       "4        E09000001  E02000001  E01000001  2004     15_19    1       0   \n",
       "...            ...        ...        ...   ...       ...  ...     ...   \n",
       "2572215  E09000011  E02006931  E01033746  2017     65_69    2       2   \n",
       "2572216  E09000011  E02006931  E01033746  2017     70_74    2       2   \n",
       "2572217  E09000011  E02006931  E01033746  2017     75_79    2       4   \n",
       "2572218  E09000011  E02006931  E01033746  2017     80_84    2       1   \n",
       "2572219  E09000011  E02006931  E01033746  2017       85+    2       5   \n",
       "\n",
       "         population  IMD.score                 name      coords.x1  \\\n",
       "0                 3      6.520  City of London 001A  532150.839566   \n",
       "1                17      6.520  City of London 001A  532150.839566   \n",
       "2                16      6.520  City of London 001A  532150.839566   \n",
       "3                 8      6.520  City of London 001A  532150.839566   \n",
       "4                10      6.520  City of London 001A  532150.839566   \n",
       "...             ...        ...                  ...            ...   \n",
       "2572215          36     22.292       Greenwich 038E  538053.851750   \n",
       "2572216          37     22.292       Greenwich 038E  538053.851750   \n",
       "2572217          33     22.292       Greenwich 038E  538053.851750   \n",
       "2572218          33     22.292       Greenwich 038E  538053.851750   \n",
       "2572219          22     22.292       Greenwich 038E  538053.851750   \n",
       "\n",
       "             coords.x2        age  \n",
       "0        181617.460916   0.056495  \n",
       "1        181617.460916   2.638939  \n",
       "2        181617.460916   7.500000  \n",
       "3        181617.460916  12.500000  \n",
       "4        181617.460916  17.652159  \n",
       "...                ...        ...  \n",
       "2572215  177045.460068  67.631902  \n",
       "2572216  177045.460068  72.413336  \n",
       "2572217  177045.460068  77.369979  \n",
       "2572218  177045.460068  82.260847  \n",
       "2572219  177045.460068  89.966813  \n",
       "\n",
       "[2572220 rows x 13 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mortality = pd.merge(mortality, centroids)\n",
    "# mortality = pd.merge(mortality, age_df)\n",
    "mortality[\"age\"] = mortality[\"age_group\"].map(age_dict)\n",
    "mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mortality.to_csv(\"mortality.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work on men only for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mortality_m = mortality[mortality[\"sex\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on all the data coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.2376e+05, 1.7928e+05, 2.0040e+03, 5.6495e-02],\n",
       "        [5.2376e+05, 1.7928e+05, 2.0040e+03, 2.6389e+00],\n",
       "        [5.2376e+05, 1.7928e+05, 2.0040e+03, 7.5000e+00],\n",
       "        ...,\n",
       "        [5.2633e+05, 1.7617e+05, 2.0170e+03, 7.7370e+01],\n",
       "        [5.2633e+05, 1.7617e+05, 2.0170e+03, 8.2261e+01],\n",
       "        [5.2633e+05, 1.7617e+05, 2.0170e+03, 8.9967e+01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = mortality_m[[\"coords.x1\", \"coords.x2\", \"YEAR\", \"age\"]]\n",
    "test_x = torch.tensor(test_x.values)\n",
    "test_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only train on data with non-negative populations. Zero population strata provide no information and will not work with log link offset in the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAD2011</th>\n",
       "      <th>MSOA2011</th>\n",
       "      <th>LSOA2011</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>age_group</th>\n",
       "      <th>sex</th>\n",
       "      <th>deaths</th>\n",
       "      <th>population</th>\n",
       "      <th>IMD.score</th>\n",
       "      <th>name</th>\n",
       "      <th>coords.x1</th>\n",
       "      <th>coords.x2</th>\n",
       "      <th>age</th>\n",
       "      <th>death rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>E02000381</td>\n",
       "      <td>E01001851</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>16.280</td>\n",
       "      <td>Hammersmith and Fulham 010A</td>\n",
       "      <td>523756.537745</td>\n",
       "      <td>179279.977178</td>\n",
       "      <td>0.056495</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>E02000381</td>\n",
       "      <td>E01001851</td>\n",
       "      <td>2004</td>\n",
       "      <td>1_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>16.280</td>\n",
       "      <td>Hammersmith and Fulham 010A</td>\n",
       "      <td>523756.537745</td>\n",
       "      <td>179279.977178</td>\n",
       "      <td>2.638939</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>E02000381</td>\n",
       "      <td>E01001851</td>\n",
       "      <td>2004</td>\n",
       "      <td>5_9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>16.280</td>\n",
       "      <td>Hammersmith and Fulham 010A</td>\n",
       "      <td>523756.537745</td>\n",
       "      <td>179279.977178</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>E02000381</td>\n",
       "      <td>E01001851</td>\n",
       "      <td>2004</td>\n",
       "      <td>10_14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>16.280</td>\n",
       "      <td>Hammersmith and Fulham 010A</td>\n",
       "      <td>523756.537745</td>\n",
       "      <td>179279.977178</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>E02000381</td>\n",
       "      <td>E01001851</td>\n",
       "      <td>2004</td>\n",
       "      <td>15_19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>16.280</td>\n",
       "      <td>Hammersmith and Fulham 010A</td>\n",
       "      <td>523756.537745</td>\n",
       "      <td>179279.977178</td>\n",
       "      <td>17.652159</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60092</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>E02000394</td>\n",
       "      <td>E01032790</td>\n",
       "      <td>2017</td>\n",
       "      <td>65_69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>21.194</td>\n",
       "      <td>Hammersmith and Fulham 023F</td>\n",
       "      <td>526330.848297</td>\n",
       "      <td>176173.601903</td>\n",
       "      <td>67.631902</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60093</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>E02000394</td>\n",
       "      <td>E01032790</td>\n",
       "      <td>2017</td>\n",
       "      <td>70_74</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>21.194</td>\n",
       "      <td>Hammersmith and Fulham 023F</td>\n",
       "      <td>526330.848297</td>\n",
       "      <td>176173.601903</td>\n",
       "      <td>72.413336</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60094</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>E02000394</td>\n",
       "      <td>E01032790</td>\n",
       "      <td>2017</td>\n",
       "      <td>75_79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>21.194</td>\n",
       "      <td>Hammersmith and Fulham 023F</td>\n",
       "      <td>526330.848297</td>\n",
       "      <td>176173.601903</td>\n",
       "      <td>77.369979</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60095</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>E02000394</td>\n",
       "      <td>E01032790</td>\n",
       "      <td>2017</td>\n",
       "      <td>80_84</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>21.194</td>\n",
       "      <td>Hammersmith and Fulham 023F</td>\n",
       "      <td>526330.848297</td>\n",
       "      <td>176173.601903</td>\n",
       "      <td>82.260847</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60096</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>E02000394</td>\n",
       "      <td>E01032790</td>\n",
       "      <td>2017</td>\n",
       "      <td>85+</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21.194</td>\n",
       "      <td>Hammersmith and Fulham 023F</td>\n",
       "      <td>526330.848297</td>\n",
       "      <td>176173.601903</td>\n",
       "      <td>89.966813</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29924 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LAD2011   MSOA2011   LSOA2011  YEAR age_group  sex  deaths  \\\n",
       "0      E09000013  E02000381  E01001851  2004         0    1       0   \n",
       "1      E09000013  E02000381  E01001851  2004       1_4    1       0   \n",
       "2      E09000013  E02000381  E01001851  2004       5_9    1       0   \n",
       "3      E09000013  E02000381  E01001851  2004     10_14    1       0   \n",
       "4      E09000013  E02000381  E01001851  2004     15_19    1       0   \n",
       "...          ...        ...        ...   ...       ...  ...     ...   \n",
       "60092  E09000013  E02000394  E01032790  2017     65_69    1       0   \n",
       "60093  E09000013  E02000394  E01032790  2017     70_74    1       3   \n",
       "60094  E09000013  E02000394  E01032790  2017     75_79    1       0   \n",
       "60095  E09000013  E02000394  E01032790  2017     80_84    1       3   \n",
       "60096  E09000013  E02000394  E01032790  2017       85+    1       0   \n",
       "\n",
       "       population  IMD.score                         name      coords.x1  \\\n",
       "0              19     16.280  Hammersmith and Fulham 010A  523756.537745   \n",
       "1              49     16.280  Hammersmith and Fulham 010A  523756.537745   \n",
       "2              38     16.280  Hammersmith and Fulham 010A  523756.537745   \n",
       "3              28     16.280  Hammersmith and Fulham 010A  523756.537745   \n",
       "4              51     16.280  Hammersmith and Fulham 010A  523756.537745   \n",
       "...           ...        ...                          ...            ...   \n",
       "60092          13     21.194  Hammersmith and Fulham 023F  526330.848297   \n",
       "60093          24     21.194  Hammersmith and Fulham 023F  526330.848297   \n",
       "60094          12     21.194  Hammersmith and Fulham 023F  526330.848297   \n",
       "60095          18     21.194  Hammersmith and Fulham 023F  526330.848297   \n",
       "60096           5     21.194  Hammersmith and Fulham 023F  526330.848297   \n",
       "\n",
       "           coords.x2        age  death rate  \n",
       "0      179279.977178   0.056495    0.000000  \n",
       "1      179279.977178   2.638939    0.000000  \n",
       "2      179279.977178   7.500000    0.000000  \n",
       "3      179279.977178  12.500000    0.000000  \n",
       "4      179279.977178  17.652159    0.000000  \n",
       "...              ...        ...         ...  \n",
       "60092  176173.601903  67.631902    0.000000  \n",
       "60093  176173.601903  72.413336    0.125000  \n",
       "60094  176173.601903  77.369979    0.000000  \n",
       "60095  176173.601903  82.260847    0.166667  \n",
       "60096  176173.601903  89.966813    0.000000  \n",
       "\n",
       "[29924 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mortality_m = mortality_m[mortality_m[\"population\"] != 0]\n",
    "mortality_m[\"death rate\"] = mortality_m[\"deaths\"]/mortality_m[\"population\"]\n",
    "mortality_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0643,  0.5770, -1.6170, -1.5620],\n",
       "        [-0.0643,  0.5770, -1.6170, -1.4673],\n",
       "        [-0.0643,  0.5770, -1.6170, -1.2890],\n",
       "        ...,\n",
       "        [ 2.0518, -1.4541,  1.6098,  1.2735],\n",
       "        [ 2.0518, -1.4541,  1.6098,  1.4529],\n",
       "        [ 2.0518, -1.4541,  1.6098,  1.7355]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = mortality_m[[\"coords.x1\", \"coords.x2\", \"YEAR\", \"age\"]]\n",
    "# rescale the columns because GP regression works better when the mean is around zero (standardise)\n",
    "train_x = train_x.apply(lambda x: (x - x.mean()) / x.std())\n",
    "train_x = torch.tensor(train_x.values)\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        ...,\n",
       "        [0.0000],\n",
       "        [0.1667],\n",
       "        [0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = mortality_m[[\"death rate\"]]\n",
    "train_y = torch.tensor(train_y.values)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually, for now, let's just focus on age vs death rate as it is a much smaller test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>deaths</th>\n",
       "      <th>population</th>\n",
       "      <th>death rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.056495</td>\n",
       "      <td>70</td>\n",
       "      <td>18002</td>\n",
       "      <td>0.003888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.638939</td>\n",
       "      <td>10</td>\n",
       "      <td>62638</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>11</td>\n",
       "      <td>64941</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>12</td>\n",
       "      <td>53969</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.652159</td>\n",
       "      <td>36</td>\n",
       "      <td>57225</td>\n",
       "      <td>0.000629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.520970</td>\n",
       "      <td>68</td>\n",
       "      <td>104824</td>\n",
       "      <td>0.000649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27.519790</td>\n",
       "      <td>112</td>\n",
       "      <td>159261</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32.550242</td>\n",
       "      <td>119</td>\n",
       "      <td>155465</td>\n",
       "      <td>0.000765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37.697733</td>\n",
       "      <td>117</td>\n",
       "      <td>122318</td>\n",
       "      <td>0.000957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42.763704</td>\n",
       "      <td>177</td>\n",
       "      <td>94708</td>\n",
       "      <td>0.001869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47.717748</td>\n",
       "      <td>231</td>\n",
       "      <td>76349</td>\n",
       "      <td>0.003026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>52.772916</td>\n",
       "      <td>330</td>\n",
       "      <td>61716</td>\n",
       "      <td>0.005347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>57.707022</td>\n",
       "      <td>536</td>\n",
       "      <td>50280</td>\n",
       "      <td>0.010660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>62.638925</td>\n",
       "      <td>713</td>\n",
       "      <td>40609</td>\n",
       "      <td>0.017558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>67.631902</td>\n",
       "      <td>936</td>\n",
       "      <td>34169</td>\n",
       "      <td>0.027393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>72.413336</td>\n",
       "      <td>1213</td>\n",
       "      <td>27010</td>\n",
       "      <td>0.044909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>77.369979</td>\n",
       "      <td>1386</td>\n",
       "      <td>20340</td>\n",
       "      <td>0.068142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>82.260847</td>\n",
       "      <td>1752</td>\n",
       "      <td>13476</td>\n",
       "      <td>0.130009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>89.966813</td>\n",
       "      <td>1663</td>\n",
       "      <td>9655</td>\n",
       "      <td>0.172242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  deaths  population  death rate\n",
       "0    0.056495      70       18002    0.003888\n",
       "1    2.638939      10       62638    0.000160\n",
       "2    7.500000      11       64941    0.000169\n",
       "3   12.500000      12       53969    0.000222\n",
       "4   17.652159      36       57225    0.000629\n",
       "5   22.520970      68      104824    0.000649\n",
       "6   27.519790     112      159261    0.000703\n",
       "7   32.550242     119      155465    0.000765\n",
       "8   37.697733     117      122318    0.000957\n",
       "9   42.763704     177       94708    0.001869\n",
       "10  47.717748     231       76349    0.003026\n",
       "11  52.772916     330       61716    0.005347\n",
       "12  57.707022     536       50280    0.010660\n",
       "13  62.638925     713       40609    0.017558\n",
       "14  67.631902     936       34169    0.027393\n",
       "15  72.413336    1213       27010    0.044909\n",
       "16  77.369979    1386       20340    0.068142\n",
       "17  82.260847    1752       13476    0.130009\n",
       "18  89.966813    1663        9655    0.172242"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mortality_m = mortality[mortality[\"sex\"] == 1]\n",
    "mortality_m = mortality_m.groupby([\"age\"])[[\"deaths\", \"population\"]].sum().reset_index()\n",
    "mortality_m[\"death rate\"] = mortality_m[\"deaths\"]/mortality_m[\"population\"]\n",
    "mortality_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5219, -1.4300, -1.2571, -1.0792, -0.8959, -0.7227, -0.5449, -0.3659,\n",
       "        -0.1828, -0.0026,  0.1737,  0.3535,  0.5291,  0.7045,  0.8821,  1.0522,\n",
       "         1.2286,  1.4026,  1.6767], dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = mortality_m[[\"age\"]]\n",
    "# rescale the columns because GP regression works better when the mean is around zero (standardise)\n",
    "train_x = train_x.apply(lambda x: (x - x.mean()) / x.std())\n",
    "train_x = torch.tensor(train_x[\"age\"].values)\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.8885e-03, 1.5965e-04, 1.6938e-04, 2.2235e-04, 6.2910e-04, 6.4871e-04,\n",
       "        7.0325e-04, 7.6545e-04, 9.5652e-04, 1.8689e-03, 3.0256e-03, 5.3471e-03,\n",
       "        1.0660e-02, 1.7558e-02, 2.7393e-02, 4.4909e-02, 6.8142e-02, 1.3001e-01,\n",
       "        1.7224e-01], dtype=torch.float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = mortality_m[[\"death rate\"]]\n",
    "train_y = torch.tensor(train_y[\"death rate\"].values)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ba18bfea190>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3wW5Z338c8vCeEQzhDkfDSCeEKMaOtqpVaLtivaXXe1q7WtXXQrre7qPtLuoe7zbJ+XdW192l2Vta2utlttu/VAWypaqvakbQKiEI4BA4QEEkgggRByuH/PH/cEb2JIJuQw9+H7fr3ymplrrmvmd484v3uumfsac3dERCTzZEUdgIiIREMJQEQkQykBiIhkKCUAEZEMpQQgIpKhcqIOoDvGjh3r06dPjzoMEZGUsmbNmv3unt++PKUSwPTp0ykuLo46DBGRlGJmOzsqVxeQiEiGUgIQEclQoRKAmS0ysy1mVmpmyzpYP8fM3jCzY2Z2b0L5bDNbl/BXZ2Z3B+vuN7M9Ceuu6b2PJSIiXenyHoCZZQOPAFcC5UCRma1w940J1WqALwLXJbZ19y3AvITt7AGeT6jysLs/1KNPICIipyTMFcACoNTdd7h7E/AssDixgrtXuXsR0NzJdq4Atrt7hzcjRESkf4VJAJOA3QnL5UFZd90IPNOubKmZvWNmT5jZqI4amdkSMys2s+Lq6upT2K2IiHQkTAKwDsq6NYSomeUC1wI/Tih+DJhFvIuoEvh6R23d/XF3L3T3wvz89z3GKiIipyhMAigHpiQsTwYqurmfq4G17r6vrcDd97l7q7vHgG8T72oSEZEEjc2t3L+ihD0Hj/b6tsMkgCKgwMxmBN/kbwRWdHM/N9Gu+8fMJiQsXg9s6OY2RUTS3n/9voz/+n0Zu2saen3bXT4F5O4tZrYUWAVkA0+4e4mZ3RGsX25m44FiYDgQCx71nOvudWY2hPgTRLe32/SDZjaPeHdSWQfrRUQy2qGGZh59tZSFs/O5eOaYXt9+qKEg3H0lsLJd2fKE+b3Eu4Y6atsAvC9yd7+lW5GKiGSYR18vpf5YC/9r0Zw+2b5+CSwikoQqDh7lyd+Vcf35kzhzwvA+2YcSgIhIEvp/v9wKDn935Rl9tg8lABGRJLNtXz3/s6acWz4wjcmjhvTZfpQARESSzIOrtpCXm8OdC0/v0/0oAYiIJJHishpe2biP2z80k9F5uX26LyUAEZEk4e587aXN5A8byGf/ZEaf708JQEQkSazeVEVRWS13f6SAIbl9/8JGJQARkSTQGnMeXLWZGWPz+IvCKV036AVKACIiSeC5teVs3XeYv//obAZk98+pWQlARCRijc2tPPzKVs6bMpKrzx7fb/tVAhARidj33thJxaFG7ls0G7OORuDvG0oAIiIROnS0mf94tZQPnZHPB2eN7dd9KwGIiERo+evbqWts5r4+GvCtM0oAIiIR2XuokSd/9y6Lz5vI3Il9M+BbZ5QAREQi8s3VW2mNOfdcNTuS/SsBiIhEoLTqMD8s2s3NF09jyui+G/CtM0oAIiIReGjVFobk5rC0jwd864wSgIhIP1u7q5aXSvay5LKZjBk6MLI4lABERPqRu/PALzYzduhAbuuHAd86owQgItKPXttSzR/freGuK04nb2DfD/jWmVAJwMwWmdkWMys1s2UdrJ9jZm+Y2TEzu7fdujIzW29m68ysOKF8tJm9Ymbbgumonn8cEZHk1RqLD/c8fcwQblwwNepwuk4AZpYNPAJcDcwFbjKzue2q1QBfBB46yWYWuvs8dy9MKFsGrHb3AmB1sCwikrZeeGsPm/fWc28/DvjWmTARLABK3X2HuzcBzwKLEyu4e5W7FwHN3dj3YuCpYP4p4LputBURSSmNza1845WtnDNpBNecPSHqcIBwCWASsDthuTwoC8uBl81sjZktSSg/zd0rAYLpuI4am9kSMys2s+Lq6upu7FZEJHl8/82d7Dl4lGVXzyErq/8GfOtMmATQUaTejX1c4u7ziXch3Wlml3WjLe7+uLsXunthfn5+d5qKiCSFusZmHnm1lEsLxnLJ6f074FtnwiSAciDx9TSTgYqwO3D3imBaBTxPvEsJYJ+ZTQAIplVhtykikkoef30HtQ3RDPjWmTAJoAgoMLMZZpYL3AisCLNxM8szs2Ft88BVwIZg9Qrg1mD+VuDF7gQuIpIKquoa+c5vd3DteRM5e9KIqMM5QZcPobp7i5ktBVYB2cAT7l5iZncE65eb2XigGBgOxMzsbuJPDI0Fng9ecJAD/MDdXwo2/QDwIzO7DdgF3NC7H01EJHrfXL2NllbnnqvOiDqU9wn1KwR3XwmsbFe2PGF+L/GuofbqgPNOss0DwBWhIxURSTE7qg/zbNFubr5oKtPG5EUdzvtE/yCqiEiaeujlLQzKyeILVxREHUqHlABERPrAut0HWbl+L5+7dCZjIxzwrTNKACIivSw+4NsmxuTl8teXzYw6nJNSAhAR6WWvb63mzR01fPGKAoZGPOBbZ5QARER6USzmfO2lLUwdPYSbkmDAt84oAYiI9KIVb1ewqbKOe646g9yc5D7FJnd0IiIp5FhLKw+9vIWzJg7nT8+dGHU4XVICEBHpJT/4wy7Ka49y36LkGfCtM0oAIiK9oL6xmX//VSmXnD6GSwuSZ8C3zigBiIj0gm//egc1R5q4b9EcguFvkp4SgIhID1XVN/Kd377Lx86dwLmTR0YdTmhKACIiPfTvq0tpaolx71Wzow6lW5QARER6oGz/EZ754y5uWjCVGWOTb8C3zigBiIj0wEMvb2FAdhZfuOL0qEPpNiUAEZFTtL78ED97p5K/vnQG44YNijqcblMCEBE5RV97aTOjk3zAt84oAYiInILishp+W7qfpQtPZ9igAVGHc0qUAERETsFvtu0ny+CGwo5ehpgalABERE5B8c4a5owfnrLf/iFkAjCzRWa2xcxKzWxZB+vnmNkbZnbMzO5NKJ9iZq+a2SYzKzGzuxLW3W9me8xsXfB3Te98JBGRvtXSGuOtXQe5cPqoqEPpkS7fVGBm2cAjwJVAOVBkZivcfWNCtRrgi8B17Zq3APe4+1ozGwasMbNXEto+7O4P9fhTiIj0o02V9TQ0tVI4fXTUofRImCuABUCpu+9w9ybgWWBxYgV3r3L3IqC5XXmlu68N5uuBTcCkXolcRCQiRWU1ABSm+BVAmAQwCdidsFzOKZzEzWw6cD7wh4TipWb2jpk9YWapfSRFJGOs2VnLpJGDmTBicNSh9EiYBNDRsHbenZ2Y2VDgJ8Dd7l4XFD8GzALmAZXA10/SdomZFZtZcXV1dXd2KyLS69ydorKalO//h3AJoByYkrA8GagIuwMzG0D85P/f7v5cW7m773P3VnePAd8m3tX0Pu7+uLsXunthfn5+2N2KiPSJ3TVHqao/xgUp3v8P4RJAEVBgZjPMLBe4EVgRZuMWHxT7u8Amd/9Gu3UTEhavBzaEC1lEJDrFO+P9/+lwBdDlU0Du3mJmS4FVQDbwhLuXmNkdwfrlZjYeKAaGAzEzuxuYC5wL3AKsN7N1wSa/7O4rgQfNbB7x7qQy4Pbe/WgiIr2vqKyWYYNyOGPcsKhD6bEuEwBAcMJe2a5secL8XuJdQ+39lo7vIeDut4QPU0QkORSX1XDBtFEp8c7fruiXwCIiIR1saGJb1WEuTIP+f1ACEBEJbc3OWgAumJb6/f+gBCAiElrxzloGZBvnpdB7fzujBCAiElJxWQ1nTxrB4NzsqEPpFUoAIiIhHGtp5e3yQxSmSfcPKAGIiISyYc8hmlpiKT8AXCIlABGREIrK0usGMCgBiIiEUlxWw8yxeYwdOjDqUHqNEoCISBdiMWfNztqUH/65PSUAEZEu7Nh/mNqGZgqnpU//PygBiIh0qa3/X1cAIiIZprisljF5ucwYmxd1KL1KCUBEpAvFO+MDwMVHuE8fSgAiIp2oqm9k54GGtBkALpESgIhIJ9a0Pf+fZv3/oAQgItKporJaBuZkcfbEEVGH0uuUAEREOrFmZw3zpowkNyf9Tpfp94lERHpJQ1MLGyrq0u7xzzZKACIiJ7Fu10FaY55WA8AlUgIQETmJ4p21mMH8qRl8BWBmi8xsi5mVmtmyDtbPMbM3zOyYmd0bpq2ZjTazV8xsWzBNzyMsIimrqKyG2acNY8TgAVGH0ie6TABmlg08AlwNzAVuMrO57arVAF8EHupG22XAancvAFYHyyIiSaE15ry162Da9v9DuCuABUCpu+9w9ybgWWBxYgV3r3L3IqC5G20XA08F808B153iZxAR6XWb99Zx+FhL2g0AlyhMApgE7E5YLg/Kwuis7WnuXgkQTMd1tAEzW2JmxWZWXF1dHXK3IiI9U5ymA8AlCpMAOhr8wkNuvydt45XdH3f3QncvzM/P705TEZFTVlRWw4QRg5g0cnDUofSZMAmgHJiSsDwZqAi5/c7a7jOzCQDBtCrkNkVE+pS7U1xWm5YDwCUKkwCKgAIzm2FmucCNwIqQ2++s7Qrg1mD+VuDF8GGLiPSdPQePsreuMS0HgEuU01UFd28xs6XAKiAbeMLdS8zsjmD9cjMbDxQDw4GYmd0NzHX3uo7aBpt+APiRmd0G7AJu6O0PJyJyKtbsTP/+fwiRAADcfSWwsl3Z8oT5vcS7d0K1DcoPAFd0J1gRkf5QVFbD0IE5zBk/POpQ+pR+CSwi0k5xWS3nTx1Jdlb69v+DEoCIyAkOHW1my776tO//ByUAEZETrN1VizsUTkvv/n9QAhAROUFxWQ3ZWca8qSOjDqXPKQGIiCQoLqvlrInDGZIb6hmZlKYEICISaGqJsW73wbQe/yeREoCISGBDxSGOtcS4MM2f/2+jBCAiElgTDAB3gRKAiEhmKSqrYdqYIYwbNijqUPqFEoCICPEB4NbsrM2Y/n9QAhARAeDd/Uc4cKQp7cf/SaQEICLCey+AyZQbwKAEICICQPHOGkYOGcDMsUOjDqXfKAGIiBC/AiicNoqsNB8ALpESgIhkvP2Hj7Fj/xEKM2AAuERKACKS8Y6/ACYDBoBLpAQgIhmvuKyG3Jwszpk8IupQ+pUSgIhkvKKyWs6bPIKBOdlRh9KvlABEJKMdbWqlpOIQF2TQD8DaKAGISEZ7u/wgza2eUc//twmVAMxskZltMbNSM1vWwXozs28F698xs/lB+WwzW5fwV2dmdwfr7jezPQnrrundjyYi0rW2G8AXZNgNYIAu33hgZtnAI8CVQDlQZGYr3H1jQrWrgYLg7yLgMeAid98CzEvYzh7g+YR2D7v7Q73xQURETkVRWQ0F44Yyckhu1KH0uzBXAAuAUnff4e5NwLPA4nZ1FgNPe9ybwEgzm9CuzhXAdnff2eOoRUR6QSwWDACXYc//twmTACYBuxOWy4Oy7ta5EXimXdnSoMvoCTPr8PrLzJaYWbGZFVdXV4cIV0QknK1V9dQ3tmTc8/9twiSAjn4X7d2pY2a5wLXAjxPWPwbMIt5FVAl8vaOdu/vj7l7o7oX5+fkhwhURCafo+ABwugI4mXJgSsLyZKCim3WuBta6+762Anff5+6t7h4Dvk28q0lEpN8Ul9UwbthApoweHHUokQiTAIqAAjObEXyTvxFY0a7OCuBTwdNAFwOH3L0yYf1NtOv+aXeP4HpgQ7ejFxHpgeKyWgqnj8IscwaAS9TlU0Du3mJmS4FVQDbwhLuXmNkdwfrlwErgGqAUaAA+09bezIYQf4Lo9nabftDM5hHvKirrYL2ISJ+pOHiUPQePctufzIg6lMh0mQAA3H0l8ZN8YtnyhHkH7jxJ2wZgTAflt3QrUhGRXlTcNgBcBv4ArI1+CSwiGWlNWQ1DcrOZO2F41KFERglARDJOa8z5Tel+5k0ZSU525p4GM/eTi0jG+t4bZeyoPsKNC6ZGHUqklABEJKNUHjrKv63awmVn5POn57YfsCCzKAGISEb5yosltLrz1evOztjHP9soAYhIxlhVspeXN+7jrivOYMroIVGHEzklABHJCPWNzXzlxRLmjB/G5y7N3Gf/E4X6HYCISKr7+stb2VffyGM3z2dABj/5k0hHQUTS3rrdB3nqjTJuuXga50/N3B9+tacEICJprbk1xpeeW8+4YQP5+4/OjjqcpKIuIBFJa0/+7l02Vdax/Ob5DBs0IOpwkoquAEQkbe2uaeDhV7bxkTNP46NnjY86nKSjBCAiacnd+acXN5Bl8L8Xn5Xxz/x3RAlARNLSz96p5LUt1dxz1WwmjszMF750RQlARNLOoYZm/uWnGzl38ghu/eD0qMNJWroJLCJp54GXNlPb0MR/feZCsrPU9XMyugIQkbRSVFbDM3/cxWcvmc7Zk0ZEHU5SUwIQkbTR1BLjy8+tZ9LIwfztlWdEHU7SUxeQiKSN/3x9O9uqDvPkpy9kSK5Ob13RFYCIpIUd1Yf591dL+di5E1g4Z1zU4aSEUAnAzBaZ2RYzKzWzZR2sNzP7VrD+HTObn7CuzMzWm9k6MytOKB9tZq+Y2bZgqgE6ROSUuDv/8PwGBuZk8ZWPz406nJTRZQIws2zgEeBqYC5wk5m1P8JXAwXB3xLgsXbrF7r7PHcvTChbBqx29wJgdbAsItJtP1m7hzd2HOC+RXMYN3xQ1OGkjDBXAAuAUnff4e5NwLPA4nZ1FgNPe9ybwEgz6+pda4uBp4L5p4DruhG3iAgANUea+OrPN3LBtFF8MsPf8dtdYRLAJGB3wnJ5UBa2jgMvm9kaM1uSUOc0d68ECKYddtqZ2RIzKzaz4urq6hDhikgm+defb6S+sYX/e/05ZOmZ/24JkwA6OqLejTqXuPt84t1Ed5rZZd2ID3d/3N0L3b0wPz+/O01FJM39rnQ/z63dw+0fmsns8cOiDiflhEkA5cCUhOXJQEXYOu7eNq0CnifepQSwr62bKJhWdTd4Eclcjc2t/MPz65k+Zghf+HBB1OGkpDAJoAgoMLMZZpYL3AisaFdnBfCp4Gmgi4FD7l5pZnlmNgzAzPKAq4ANCW1uDeZvBV7s4WcRkQzyH78qpexAA1+9/hwGDciOOpyU1OUvJdy9xcyWAquAbOAJdy8xszuC9cuBlcA1QCnQAHwmaH4a8HwwDGsO8AN3fylY9wDwIzO7DdgF3NBrn0pE0trWffUsf307nzh/EpecPjbqcFKWubfvzk9ehYWFXlxc3HVFEUlbR5ta+bPHfk/FoaOs/rsPMWbowKhDSnpmtqbdY/iAhoIQkRTi7tz3k3fYtLeOJz59oU7+PaShIEQkZXz7NztY8XYF9141m4WzNdxDTykBiEhK+PXWah74xWauOWc8n798VtThpAUlABFJejsPHOELz7zFGacN49/+/Dy937eXKAGISFI7cqyFJU+vAeDxWwrJG6hbl71FCUBEkpa7c++P32ZbVT3/8cnzmTpmSNQhpRUlABFJWo++tp1fbNjLl64+k0sLNBRMb1MCEJGk9KvN+3jo5S0snjeRz106I+pw0pISgIgkne3Vh7nrmXXMnTCcBz5xrm769hElABFJKvWNzSx5upgBOVn85y0XMDhX4/z0Fd1OF5GkEYs5f/vDtyk70MD3b7uIyaN007cv6QpARJLGN1dv45eb9vFPHzuTD8waE3U4aU8JQESSwqqSvXxz9Tb+/ILJ3PrB6VGHkxGUAEQkctv21fN3P1zHeZNH8K/Xna2bvv1ECUBEInXoaDNLvreGwbk5LL/lAr3cpR8pAYhIZFpjzl3PvkV5bQPLb57PhBGDow4po+gpIBGJzDde2cJrW6r56vVnUzh9dNThZBxdAYhIJH7+TiWPvLqdmxZM5a8umhZ1OBlJCUBE+t2myjru/fHbXDBtFPdfOzfqcDJWqARgZovMbIuZlZrZsg7Wm5l9K1j/jpnND8qnmNmrZrbJzErM7K6ENveb2R4zWxf8XdN7H0tEktVLGyq5+Tt/YPjgHB77q/kMzNFN36h0eQ/AzLKBR4ArgXKgyMxWuPvGhGpXAwXB30XAY8G0BbjH3dea2TBgjZm9ktD2YXd/qPc+jogkq5ojTXxlRQk/fbuCsycN5+G/mMe44YOiDiujhbkJvAAodfcdAGb2LLAYSEwAi4Gn3d2BN81spJlNcPdKoBLA3evNbBMwqV1bEUlzL23Yyz++sJ5DR5u558ozuOPyWQzIVg901MIkgEnA7oTlcuLf7ruqM4ng5A9gZtOB84E/JNRbamafAoqJXynUtt+5mS0BlgBMnTo1RLgikixqg2/9K96u4KyJw/nebRdx5oThUYclgTApuKOf5Hl36pjZUOAnwN3uXhcUPwbMAuYRTxRf72jn7v64uxe6e2F+vl4IIZIqVpXs5cqHf83K9ZX87UfO4IU7L9HJP8mEuQIoB6YkLE8GKsLWMbMBxE/+/+3uz7VVcPd9bfNm9m3gZ92KXESSUu2RJu7/aQkvrqtg7oThPP3ZBcydqBN/MgqTAIqAAjObAewBbgQ+2a7OCuLdOc8S7x465O6VFh/Q47vAJnf/RmKDhHsEANcDG3rwOUQkCbxcspcvP7+Bgw1N3P2RAu5ceLr6+pNYlwnA3VvMbCmwCsgGnnD3EjO7I1i/HFgJXAOUAg3AZ4LmlwC3AOvNbF1Q9mV3Xwk8aGbziHcVlQG399qnEpF+dbChiX/56Uaef2sPZ04YzlOfvZCzJo6IOizpgsUf3EkNhYWFXlxcHHUYIpLglxv38aXn11N7pIk7F57OnQtPJzdH3/qTiZmtcffC9uUaC0hETsmhhmb+5WclPLd2D3PGD+PJT1/I2ZP0rT+VKAGISLf9avM+vvTcevYfbuKLHz6dpR8u0Lf+FKQEICKhbayo45FXS/n5+krmjB/Gd2/Vt/5UpgQgIl0qLqvh0de286vNVQwdmMNdVxSorz8NKAGISIfcnde3VvPoq9v5Y1kNo/NyuefKM/jUB6YzYsiAqMOTXqAEICInaI05L23Yy6OvlVJSUceEEYP4yp/O5S8vnMKQXJ0y0on+a4oIAE0tMV54aw/LX9/Ojv1HmDk2jwf//FyumzdJXT1pSglAJMM1NLXwzB93853f7KDyUCNnTRzOo381n4+eNZ7srI6G+ZJ0oQQgkqEONTTz1BtlPPm7d6ltaGbBjNE88GfnclnBWOKjuEi6UwIQyTBVdY1897fv8v03d3KkqZUPzxnH5y+fpZeyZyAlAJEM0NIa47el+3lu7R5eKtlLS2uMj507kb/50CyN1JnBlABE0tjGijqeW1vOC+sq2H/4GCMGD+AvC6dw25/MYPrYvKjDk4gpAYikmX11jbzw1h6ef2sPm/fWMyDbWDh7HJ+YP5mFc/L1EnY5TglAJA00NLWwqmQvz63dw+9K9xNzOH/qSP7P4rP4+LkTGZWXG3WIkoSUAERSVGvMeXPHAX6ytpyXNuyloamVyaMGs3Th6Vx3/iRm5g+NOkRJckoAIilm6756nlu7hxfe2sPeukaGDczh2vMm8on5kymcNoosPbsvISkBiCSpppYYOw8cYXv1EbZXH2Z79WE2VtSxeW892VnG5Wfk848fP5OPnHkagwaoX1+6LyMSQFV9I1lmjB06MOpQRN7nYENT/ARf9d6Jfnv1EXbVNNAae++NfeOHD2LWuDz++eNzuXbeRP17lh7LiATwjZe38sK6Pdx80TSWXDaTccMHRR2SZBB350hTK9X1x3h3/2F2tH2jD074B440Ha+bm53FjLF5nDlhGB87ZwKzxuUxK38oM/OHMnRgRvzvKv0oI/5Ffe7SmTS1xHjy92U8/eZOPrlgKrd/aCYTRgyOOjRJQU0tMWobmqg50kTtkSYOHGk6yXIztUeaqGlooqkldsI2RuflMis/jyvnnsas/KHHT/STRw3R+DvSb0K9FN7MFgHfBLKB77j7A+3WW7D+GqAB+LS7r+2srZmNBn4ITAfKgL9w99rO4ujpS+F3HjjCo69u5ydry8ky44bCyfzN5bOYPGrIKW9TUk8s5hxpaqGusYX6xmbqjrZQd7SZ+mOJ88G0sYW6xmbqjjZT2xA/odcfaznptkcMHsDovFxGDRnA6LyBjM4bwKi8XEYPyWV0Xi4z8/OYOXaoHsuUfnWyl8J3mQDMLBvYClwJlANFwE3uvjGhzjXAF4gngIuAb7r7RZ21NbMHgRp3f8DMlgGj3P2+zmLpaQJos7umgeWvb+fHxeXE3Pmz+ZP5/MJZTBuTXL+MdHeaW52m1hjNLTGaWmM0tcQ41hKfNre+V3a8PKgbC/67nvBf19smnrCP960+Xu54MI0XeFt54nwQZ+K2Etu5814sfmL58XonbK9dHXdaY05r2zTmxIL5lpgTizmtHj+pHy/zdvVancPH3juRHz7WQqyL7z2DBmQxfNAAhg3KYfjgAQwbNIDRQ947mY/Ky2VMXnwaP+HHT/o52Ro2WZLPyRJAmC6gBUCpu+8INvQssBjYmFBnMfC0x88Eb5rZSDObQPzb/cnaLgYuD9o/BbwGdJoAesuU0UP46vXnsPTDp/Ofr+/gmT/u4n/WljOjg5/Gd5QgT3ruSDghvv8k99722tbFm7z/hNfUEuNYcGLPFGZggJkFUzAMM8jOsvf+zMgKponlWcfrZZGdxfF6OVlGlhkTRw5izqBhx0/oiSf3E+dzGDZogMa/l4wQJgFMAnYnLJcT/5bfVZ1JXbQ9zd0rAdy90szGdbRzM1sCLAGYOnVqiHDDmzBiMPdfexafv3wWT/6+jF0HGjqu2EGX7Ml6aU88gb23TMIJrW19vDgoCyplGeTmZJGbk8XA7Kzj8wPa5oPpwA7KEsuzEobzTRzZt22Y38T4T1jPie06jv3EkzR24udt274Zx+OwzrahoYdFIhEmAXT0f2f7L8EnqxOmbafc/XHgcYh3AXWnbVjjhg/ivkVz+mLTIiJJK8x1bjkwJWF5MlARsk5nbfcF3UQE06rwYYuISE+FSQBFQIGZzTCzXOBGYEW7OiuAT1ncxcChoHuns7YrgFuD+VuBF3v4WUREpBu67AJy9xYzWwqsIv4o5xPuXmJmdwTrlwMriT8BVEr8MdDPdNY22PQDwI/M7DZgF3BDr34yERHpVKjfASSL3noMVEQkk5zsMVA96yYiknh9adQAAAOXSURBVKGUAEREMpQSgIhIhlICEBHJUCl1E9jMqoGdPdzMWGB/L4QTlVSOP5VjB8UfpVSOHaKPf5q757cvTKkE0BvMrLiju+GpIpXjT+XYQfFHKZVjh+SNX11AIiIZSglARCRDZWICeDzqAHooleNP5dhB8UcplWOHJI0/4+4BiIhIXCZeAYiICEoAIiIZK+0TgJndYGYlZhYzs5M+hmVmZWa23szWmVnSjDjXjfgXmdkWMysN3rEcOTMbbWavmNm2YDrqJPWS6th3dSyDYc+/Fax/x8zmRxFnR0LEfrmZHQqO9Toz++co4uyImT1hZlVmtuEk65P2uEOo+JPv2Mdf1J2+f8CZwGzi7xwu7KReGTA26nhPJX7iQ21vB2YCucDbwNwkiP1BYFkwvwz4WrIf+zDHkvjQ578g/sa7i4E/RB13N2K/HPhZ1LGeJP7LgPnAhpOsT8rj3o34k+7Yp/0VgLtvcvctUcdxqkLGvwAodfcd7t4EPAss7vvourQYeCqYfwq4LsJYwgpzLBcDT3vcm8DItrfbRSxZ/x2E4u6/Bmo6qZKsxx0IFX/SSfsE0A0OvGxma4IX0aeSScDuhOXyoCxqp3n8zXAE03EnqZdMxz7MsUzW4x02rg+Y2dtm9gszO6t/QusVyXrcuyOpjn2Yl8InPTP7JTC+g1X/4O5hXzV5ibtXmNk44BUz2xxk9D7XC/FbB2X98nxvZ7F3YzORHfsOhDmWkR3vLoSJay3xcWEOm9k1wAtAQZ9H1juS9biHlXTHPi0SgLt/pBe2URFMq8zseeKX0/1yEuqF+MuBKQnLk4GKHm4zlM5iN7N9ZjbB3SuDS/Wqk2wjsmPfgTDHMrLj3YUu43L3uoT5lWb2qJmNdfdUGGgtWY97KMl47NUFBJhZnpkNa5sHrgI6vJOfpIqAAjObYWa5wI3AiohjgngMtwbztwLvu5pJwmMf5liuAD4VPJVyMXCorasrYl3GbmbjzcyC+QXEzwEH+j3SU5Osxz2UpDz2Ud+F7us/4Hri3xyOAfuAVUH5RGBlMD+T+BMTbwMlxLteIo89bPzB8jXAVuJPgSRF/MAYYDWwLZiOToVj39GxBO4A7gjmDXgkWL+eTp4uS8LYlwbH+W3gTeCDUcecEPszQCXQHPybvy1VjnvI+JPu2GsoCBGRDKUuIBGRDKUEICKSoZQAREQylBKAiEiGUgIQEclQSgAiIhlKCUBEJEP9f2S6GD/8Zt80AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_x.numpy(), train_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple GP regression\n",
    "Let's ignore the Poisson/Negative Binonmial likelihood for now and just get a GP regression setup working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal model hyperparameters\n",
    "# model.double()\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    likelihood = likelihood.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200 - Loss: -2.717   lengthscale: 1.075   noise: 0.000\n",
      "Iter 2/200 - Loss: -2.669   lengthscale: 1.142   noise: 0.000\n",
      "Iter 3/200 - Loss: -2.718   lengthscale: 1.092   noise: 0.000\n",
      "Iter 4/200 - Loss: -2.711   lengthscale: 1.057   noise: 0.000\n",
      "Iter 5/200 - Loss: -2.697   lengthscale: 1.063   noise: 0.000\n",
      "Iter 6/200 - Loss: -2.705   lengthscale: 1.090   noise: 0.000\n",
      "Iter 7/200 - Loss: -2.721   lengthscale: 1.127   noise: 0.000\n",
      "Iter 8/200 - Loss: -2.729   lengthscale: 1.167   noise: 0.000\n",
      "Iter 9/200 - Loss: -2.725   lengthscale: 1.199   noise: 0.000\n",
      "Iter 10/200 - Loss: -2.719   lengthscale: 1.215   noise: 0.000\n",
      "Iter 11/200 - Loss: -2.719   lengthscale: 1.215   noise: 0.000\n",
      "Iter 12/200 - Loss: -2.725   lengthscale: 1.203   noise: 0.000\n",
      "Iter 13/200 - Loss: -2.731   lengthscale: 1.185   noise: 0.000\n",
      "Iter 14/200 - Loss: -2.733   lengthscale: 1.165   noise: 0.000\n",
      "Iter 15/200 - Loss: -2.731   lengthscale: 1.148   noise: 0.000\n",
      "Iter 16/200 - Loss: -2.729   lengthscale: 1.138   noise: 0.000\n",
      "Iter 17/200 - Loss: -2.728   lengthscale: 1.137   noise: 0.000\n",
      "Iter 18/200 - Loss: -2.731   lengthscale: 1.143   noise: 0.000\n",
      "Iter 19/200 - Loss: -2.734   lengthscale: 1.153   noise: 0.000\n",
      "Iter 20/200 - Loss: -2.736   lengthscale: 1.166   noise: 0.000\n",
      "Iter 21/200 - Loss: -2.736   lengthscale: 1.176   noise: 0.000\n",
      "Iter 22/200 - Loss: -2.735   lengthscale: 1.181   noise: 0.000\n",
      "Iter 23/200 - Loss: -2.734   lengthscale: 1.178   noise: 0.000\n",
      "Iter 24/200 - Loss: -2.735   lengthscale: 1.168   noise: 0.000\n",
      "Iter 25/200 - Loss: -2.738   lengthscale: 1.153   noise: 0.000\n",
      "Iter 26/200 - Loss: -2.739   lengthscale: 1.135   noise: 0.000\n",
      "Iter 27/200 - Loss: -2.739   lengthscale: 1.117   noise: 0.000\n",
      "Iter 28/200 - Loss: -2.738   lengthscale: 1.103   noise: 0.000\n",
      "Iter 29/200 - Loss: -2.738   lengthscale: 1.094   noise: 0.000\n",
      "Iter 30/200 - Loss: -2.739   lengthscale: 1.089   noise: 0.000\n",
      "Iter 31/200 - Loss: -2.740   lengthscale: 1.089   noise: 0.000\n",
      "Iter 32/200 - Loss: -2.740   lengthscale: 1.090   noise: 0.000\n",
      "Iter 33/200 - Loss: -2.739   lengthscale: 1.091   noise: 0.000\n",
      "Iter 34/200 - Loss: -2.739   lengthscale: 1.091   noise: 0.000\n",
      "Iter 35/200 - Loss: -2.740   lengthscale: 1.089   noise: 0.000\n",
      "Iter 36/200 - Loss: -2.740   lengthscale: 1.084   noise: 0.000\n",
      "Iter 37/200 - Loss: -2.741   lengthscale: 1.077   noise: 0.000\n",
      "Iter 38/200 - Loss: -2.740   lengthscale: 1.071   noise: 0.000\n",
      "Iter 39/200 - Loss: -2.740   lengthscale: 1.066   noise: 0.000\n",
      "Iter 40/200 - Loss: -2.740   lengthscale: 1.063   noise: 0.000\n",
      "Iter 41/200 - Loss: -2.741   lengthscale: 1.062   noise: 0.000\n",
      "Iter 42/200 - Loss: -2.741   lengthscale: 1.061   noise: 0.000\n",
      "Iter 43/200 - Loss: -2.741   lengthscale: 1.060   noise: 0.000\n",
      "Iter 44/200 - Loss: -2.741   lengthscale: 1.059   noise: 0.000\n",
      "Iter 45/200 - Loss: -2.741   lengthscale: 1.058   noise: 0.000\n",
      "Iter 46/200 - Loss: -2.741   lengthscale: 1.056   noise: 0.000\n",
      "Iter 47/200 - Loss: -2.741   lengthscale: 1.056   noise: 0.000\n",
      "Iter 48/200 - Loss: -2.741   lengthscale: 1.058   noise: 0.000\n",
      "Iter 49/200 - Loss: -2.741   lengthscale: 1.061   noise: 0.000\n",
      "Iter 50/200 - Loss: -2.741   lengthscale: 1.065   noise: 0.000\n",
      "Iter 51/200 - Loss: -2.741   lengthscale: 1.069   noise: 0.000\n",
      "Iter 52/200 - Loss: -2.741   lengthscale: 1.071   noise: 0.000\n",
      "Iter 53/200 - Loss: -2.741   lengthscale: 1.072   noise: 0.000\n",
      "Iter 54/200 - Loss: -2.741   lengthscale: 1.072   noise: 0.000\n",
      "Iter 55/200 - Loss: -2.742   lengthscale: 1.070   noise: 0.000\n",
      "Iter 56/200 - Loss: -2.742   lengthscale: 1.069   noise: 0.000\n",
      "Iter 57/200 - Loss: -2.741   lengthscale: 1.069   noise: 0.000\n",
      "Iter 58/200 - Loss: -2.742   lengthscale: 1.071   noise: 0.000\n",
      "Iter 59/200 - Loss: -2.742   lengthscale: 1.074   noise: 0.000\n",
      "Iter 60/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 61/200 - Loss: -2.742   lengthscale: 1.080   noise: 0.000\n",
      "Iter 62/200 - Loss: -2.742   lengthscale: 1.082   noise: 0.000\n",
      "Iter 63/200 - Loss: -2.742   lengthscale: 1.083   noise: 0.000\n",
      "Iter 64/200 - Loss: -2.742   lengthscale: 1.082   noise: 0.000\n",
      "Iter 65/200 - Loss: -2.742   lengthscale: 1.082   noise: 0.000\n",
      "Iter 66/200 - Loss: -2.742   lengthscale: 1.082   noise: 0.000\n",
      "Iter 67/200 - Loss: -2.742   lengthscale: 1.082   noise: 0.000\n",
      "Iter 68/200 - Loss: -2.742   lengthscale: 1.082   noise: 0.000\n",
      "Iter 69/200 - Loss: -2.742   lengthscale: 1.082   noise: 0.000\n",
      "Iter 70/200 - Loss: -2.742   lengthscale: 1.082   noise: 0.000\n",
      "Iter 71/200 - Loss: -2.742   lengthscale: 1.082   noise: 0.000\n",
      "Iter 72/200 - Loss: -2.742   lengthscale: 1.081   noise: 0.000\n",
      "Iter 73/200 - Loss: -2.742   lengthscale: 1.080   noise: 0.000\n",
      "Iter 74/200 - Loss: -2.742   lengthscale: 1.080   noise: 0.000\n",
      "Iter 75/200 - Loss: -2.742   lengthscale: 1.080   noise: 0.000\n",
      "Iter 76/200 - Loss: -2.742   lengthscale: 1.080   noise: 0.000\n",
      "Iter 77/200 - Loss: -2.742   lengthscale: 1.080   noise: 0.000\n",
      "Iter 78/200 - Loss: -2.742   lengthscale: 1.080   noise: 0.000\n",
      "Iter 79/200 - Loss: -2.742   lengthscale: 1.079   noise: 0.000\n",
      "Iter 80/200 - Loss: -2.742   lengthscale: 1.078   noise: 0.000\n",
      "Iter 81/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 82/200 - Loss: -2.742   lengthscale: 1.075   noise: 0.000\n",
      "Iter 83/200 - Loss: -2.742   lengthscale: 1.075   noise: 0.000\n",
      "Iter 84/200 - Loss: -2.742   lengthscale: 1.075   noise: 0.000\n",
      "Iter 85/200 - Loss: -2.742   lengthscale: 1.075   noise: 0.000\n",
      "Iter 86/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 87/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 88/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 89/200 - Loss: -2.742   lengthscale: 1.075   noise: 0.000\n",
      "Iter 90/200 - Loss: -2.742   lengthscale: 1.075   noise: 0.000\n",
      "Iter 91/200 - Loss: -2.742   lengthscale: 1.075   noise: 0.000\n",
      "Iter 92/200 - Loss: -2.742   lengthscale: 1.075   noise: 0.000\n",
      "Iter 93/200 - Loss: -2.742   lengthscale: 1.075   noise: 0.000\n",
      "Iter 94/200 - Loss: -2.742   lengthscale: 1.075   noise: 0.000\n",
      "Iter 95/200 - Loss: -2.742   lengthscale: 1.075   noise: 0.000\n",
      "Iter 96/200 - Loss: -2.742   lengthscale: 1.075   noise: 0.000\n",
      "Iter 97/200 - Loss: -2.742   lengthscale: 1.075   noise: 0.000\n",
      "Iter 98/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 99/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 100/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 101/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 102/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 103/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 104/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 105/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 106/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 107/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 108/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 109/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 110/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 111/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 112/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 113/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 114/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 115/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 116/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 117/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 118/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 119/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 120/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 121/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 122/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 123/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 124/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 125/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 126/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 127/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 128/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 129/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 130/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 131/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 132/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 133/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 134/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 135/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 136/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 137/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 138/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 139/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 140/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 141/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 142/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 143/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 144/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 145/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 146/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 147/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 148/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 149/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 150/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 151/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 152/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 153/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 154/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 155/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 156/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 157/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 158/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 159/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 160/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 161/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 162/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 163/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 164/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 165/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 166/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 167/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 168/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 169/200 - Loss: -2.742   lengthscale: 1.076   noise: 0.000\n",
      "Iter 170/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 171/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 172/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 173/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 174/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 175/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 176/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 177/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 178/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 179/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 180/200 - Loss: -2.742   lengthscale: 1.077   noise: 0.000\n",
      "Iter 181/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 182/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 183/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 184/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 185/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 186/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 187/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 188/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 189/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 190/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 191/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 192/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 193/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 194/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 195/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 196/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 197/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 198/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 199/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n",
      "Iter 200/200 - Loss: -2.743   lengthscale: 1.077   noise: 0.000\n"
     ]
    }
   ],
   "source": [
    "training_iter = 200\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model.covar_module.base_kernel.lengthscale.item(),\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. More complex likelihood\n",
    "Use the Pyro integration to use a more complicated likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6.10 (mortGP)",
   "language": "python",
   "name": "python3_mortgp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
