# Theo AO Rashid -- June 2020

# ----- BYM model -----
# Negative binomial likelihood
#
# Gaussian process over LSOAs +
# Age effects (random walk prior) +
# Age-LSOA interaction (normal prior) +
# Age-time interaction (random walk prior) +
# LSOA-time interaction (random walk prior)
# --------------------

library(rgdal)
library(spdep)
library(RCurl)
library(dplyr)
library(nimble)
library(lme4)

set.seed(1)

# ----- IMPORT DATA -----
# Mortality data
# url <- getURL("https://media.githubusercontent.com/media/theorashid/mortality-statsmodel/master/Data/mortsim.csv") # London
url <- getURL("https://raw.githubusercontent.com/theorashid/mortality-statsmodel/master/Data/mortsim_hf.csv") # Hammersmith and Fulham
mortality <- read.csv(text = url) %>%
  select(-X) # remove autogenerated column

mortality_m <- mortality %>% # Select male sex
  filter(sex == 1) %>%
  select(-sex)

# Shape data
shapefile <- readOGR(dsn = "Data/shapefiles/ldn_LSOA11",
                layer = "LSOA11_London")

# Merge with mortality
colnames(shapefile@data)[1] <- "LSOA2011"
shapefile <- merge(shapefile, distinct(select(mortality_m, LSOA2011, LSOA.id, LAD.id)))
shapefile <- shapefile[!is.na(shapefile$LSOA.id) ,] #Â remove NA rows for subsetting (Hammersmith and Fulahm)
shapefile <- shapefile[order(shapefile$LSOA.id),] # reorder on LSOA.id
row.names(shapefile@data) <- shapefile@data$LSOA.id

# get centroids
locs <- SpatialPointsDataFrame(shapefile, shapefile@data)
dists <- as.matrix(dist(locs@coords))
dists <- dists / max(dists)  # normalize to max distance of 1

# kernel function
maternKernel <- nimbleFunction(
    run = function(dists = double(2), l = double(0), sigma = double(0)) {
        returnType(double(2))
        n <- dim(dists)[1]
        result <- matrix(nrow = n, ncol = n, init = FALSE)
        sigma2 <- sigma*sigma   # calculate once
        l2 <- l*l
        for(i in 1:n)
            for(j in 1:n)
                # if-then-else statement removed for speed
                # comment out the required function (nu = 1/2, 3/2, 5/2)
                # result[i, j] <- sigma2 * exp(-dists[i,j]/l)
                # result[i, j] <- sigma2 * (1 + sqrt(3)*dists[i,j]/l) * exp(-sqrt(3)*dists[i,j]/l)
                result[i, j] <- sigma2 * (1 + sqrt(5)*dists[i,j]/l + 5*dists[i,j]^2 / (3*l2)) * exp(-sqrt(5)*dists[i,j]/l)
        return(result)
  })

# ----- INITIAL VALUES -----
# Get good initial values to avoid long burn ins.
# model with only age intercepts, LSOA intercepts and LSOA slopes
mod <- glmer(deaths ~ offset(log(population)) + LSOA.id + (1|age_group.id) + (1 + YEAR.id|LSOA.id), family = "poisson", data = subset(mortality_m, population > 0))

fixed <- coef(summary(mod))[, "Estimate"] # fixed effects
intercept <- fixed[1]
slope <- fixed[2]

bin <- ranef(mod)$LSOA.id
lsoa_int_inits <- bin$"(Intercept)"
lsoa_slope_inits <- bin$YEAR.id

bin <- ranef(mod)$age_group.id
age_inits <- bin$"(Intercept)"

initial <- list(intercept, slope, lsoa_int_inits, lsoa_slope_inits, age_inits)
names(initial) <- c("global.intercept", "global.slope", "lsoa.intercepts", "lsoa.slopes", "age.intercepts")

# Dimensions (Hammersmith and Fulham unit test second value):
# - age -- 19 (0, 1-4, 5-10, ..., 80-84, 85+)
# - LAD -- 33 or 1
# - MSOA -- 983 or 25
# - LSOA -- 4835 or 113
# - YEAR -- 14 (2004-17)

# ----- BUILD THE MODEL -----
# Indices:
# - a -- age
# - j -- space, each LSOA
# - t -- year (time)
code <- nimbleCode({
    # PRIORS
    
    # AREA TERMS
    # GP for intercepts
    mu_alpha[1:N_LSOA] <- mu0_alpha*ones[1:N_LSOA]
    cov_alpha[1:N_LSOA, 1:N_LSOA] <- maternKernel(dists[1:N_LSOA, 1:N_LSOA], l_alpha, sigma_alpha)
    alpha_LSOA[1:N_LSOA] ~ dmnorm(mu_alpha[1:N_LSOA], cov = cov_alpha[1:N_LSOA, 1:N_LSOA])
    mu0_alpha   ~ dnorm(0, sd = 100)
    sigma_alpha ~ dunif(0, 2)
    l_alpha     ~ dunif(0, 5)
    
    # GP for slopes
    mu_beta[1:N_LSOA] <- mu0_beta*ones[1:N_LSOA]
    cov_beta[1:N_LSOA, 1:N_LSOA] <- maternKernel(dists[1:N_LSOA, 1:N_LSOA], l_beta, sigma_beta)
    beta_LSOA[1:N_LSOA] ~ dmnorm(mu_beta[1:N_LSOA], cov = cov_beta[1:N_LSOA, 1:N_LSOA])
    mu0_beta   ~ dnorm(0, sd = 100)
    sigma_beta ~ dunif(0, 2)
    l_beta     ~ dunif(0, 5)
    
    # AGE TERMS
    alpha_age[1] <- 0 # initialise first terms for RW
    beta_age[1]  <- 0
    for(a in 2:N_age_groups){
        alpha_age[a] ~ dnorm(alpha_age[a-1], sd = sigma_alpha_age) # RW based on previous age group
        beta_age[a]  ~ dnorm(beta_age[a-1], sd = sigma_beta_age)
    }
    sigma_alpha_age ~ dunif(0,2)
    sigma_beta_age ~ dunif(0,2)
    
    # INTERACTIONS
    # age-LSOA interactions
    for(a in 1:N_age_groups){
        for(j in 1:N_LSOA){
            xi[a, j] ~ dnorm(alpha_age[a] + alpha_LSOA[j], sd = sigma_xi) # centred on age + LSOA
        }
    }
    sigma_xi ~ dunif(0,2)
    
    # LSOA-time interactions
    for(j in 1:N_LSOA){
        nu[j, 1] <- 0
        for(t in 2:N_year){
            # the difference between timesteps is beta_v * time (where timestep length is 1 year)
            nu[j, t] ~ dnorm(nu[j, t-1] + beta_LSOA[j], sd = sigma_nu)
        }
    }
    sigma_nu ~ dunif(0,2)
    
    # age-time interactions
    for(a in 1:N_age_groups){
        gamma[a, 1] <- 0
        for(t in 2:N_year){
            # the difference between timesteps is beta_age * time (where timestep length is 1 year)
            gamma[a, t] ~ dnorm(gamma[a, t-1] + beta_age[a], sd = sigma_gamma)
        }
    }
    sigma_gamma ~ dunif(0,2)
    
    # Put all parameters together into indexed lograte with age-LSOA-time overdispersion term
    for(a in 1:N_age_groups){
        for(j in 1:N_LSOA){
            for(t in 1:N_year){
                lograte[a, j, t] <- xi[a, j] + nu[j, t] + gamma[a, t]
            }
        }
    }
    
    # LIKELIHOOD
    # N total number of cells, i.e. ages*years*areas(*sex)
    for (i in 1:N) {
        # y is number of deaths in that cell
        # mu is predicted number of deaths in that cell
        y[i] ~ dnegbin(p[i], r)
        p[i] <- r/(r + mu[i])
        log(mu[i]) <- log(n[i]) + lograte[age[i], LSOA[i], yr[i]]
    }
    r ~ dunif(0,50)
})

constants <- list(N = nrow(mortality),
                  N_year = n_distinct(mortality$YEAR),
                  N_LSOA = n_distinct(mortality$LSOA2011),
                  N_age_groups = n_distinct(mortality$age_group),
                  dists = dists,
                  ones = rep(1, n_distinct(mortality$LSOA2011)),
                  age = mortality$age_group.id,
                  LSOA = mortality$LSOA.id, 
                  yr = mortality$YEAR.id)
data <- list(y = mortality$deaths,
             n = mortality$population)

# Initial values for uninformative priors (top-level nodes)
# mu, lograte, alpha_age, beta_age not initialised
inits <- list(mu0_alpha = initial$global.intercept,
              mu0_beta = initial$global.slope,
              alpha_LSOA = initial$lsoa.intercepts + initial$global.intercept,
              beta_LSOA = initial$lsoa.slopes + initial$global.slope,
              sigma_alpha = 0.1, sigma_beta = 0.1,
              alpha_age = initial$age.intercepts,
              sigma_alpha_age = 0.75, sigma_beta_age = 0.015,
              sigma_xi = 0.08, sigma_nu = 0.1,
              sigma_gamma = 0.1, r = 1.0)

# ----- CREATE THE MODEL -----
model <- nimbleModel(code = code, constants = constants, inits = inits, data = data) # model in R
# model$getNodeNames() # look at nodes of model's DAG
# model$plotGraph() # plot the DAG

# ----- COMPILE THE MODEL IN C-CODE -----
Cmodel <- compileNimble(model)

# ----- MCMC INTEGRATION -----
# Monitors
# Monitor the death rate per person to avoid 0 population issues
monitors <- c("lograte")
# Hyperparameter monitors to check covergence, with some thinning
sigmas <- c("sigma_alpha", "sigma_beta",
            "sigma_alpha_age", "sigma_beta_age",
            "sigma_xi", "sigma_nu",
            "sigma_gamma")
monitors2 <- c("mu0_alpha", "mu0_beta", "r", "l_alpha", "l_beta", sigmas)

# CUSTOMISABLE MCMC -- configureMCMC, buildMCMC, compileNimble, runMCMC
# 1. MCMC Configuration -- can be customised with different samplers
mcmcConf <- configureMCMC(model = Cmodel,
                          monitors = monitors, monitors2 = monitors2,
                          thin = 10, thin2 = 100, print = TRUE) # input the R model

# sample standard deviations on log scale
mcmcConf$removeSamplers(sigmas)
for (s in sigmas) {
    mcmcConf$addSampler(target = s, type = "RW", control = list(log = TRUE))
}

# 2. Build and compile the MCMC
Rmcmc <- buildMCMC(mcmcConf) # Set enableWAIC = TRUE if we need to calculate WAIC
Cmcmc <- compileNimble(Rmcmc)

# 3. Run MCMC
mcmc.out <- runMCMC(Cmcmc,
                    niter = 50000, nchains = 2, nburnin = 1000,
                    progressBar = TRUE, samples = TRUE, summary = TRUE)

# ----- SAVE OUTPUT SAMPLES AND SUMMARY -----
saveRDS(mcmc.out, file = "mcmc_out.rds")